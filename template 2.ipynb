{"cells":[{"cell_type":"markdown","id":"84b3c2c4","metadata":{"id":"84b3c2c4"},"source":["# Outlier Handling"]},{"cell_type":"code","execution_count":null,"id":"7011ef6c","metadata":{"id":"7011ef6c"},"outputs":[],"source":["num_columns = df.select_dtypes(exclude='object').columns\n","\n","## Z-score based / Standard Scaler based method\n","# -----------------------\n","# def zscore_for_column(df,col):\n","#     #zscore = (val - mean) / std_dev\n","#     zscore = (df[col] - df[col].mean())/df[col].std()\n","#     return zscore\n","\n","\n","# # calculating zscore of each column and updating it in the copy.\n","# df_std = df_ohe.copy()\n","# for col in num_columns:\n","#     df_std[col] = zscore_for_column(df,col)\n","\n","# df_std.describe()\n","\n","\n","# OR\n","#@@@@@@@@@@@@\n","# Z score / Standardscaler using library\n","\n","df_std =df_ohe.copy()\n","from sklearn.preprocessing import StandardScaler\n","sd = StandardScaler()\n","sd.fit(df_std.loc[:,num_columns]) # it will learn --> mean and std_dev\n","\n","# acually apply the formul and convert the data --> transform\n","\n","df_std.loc[:,num_columns]=sd.transform(df_std.loc[:,num_columns])\n","\n","df_std.describe()\n","\n","# ---------------------------------\n","\n","# Replacing the outliers with -3 and 3 (extreme values)\n","\n","from IPython.utils.text import columnize\n","\n","\n","def outlier_imputation(df,col):\n","    df.loc[df[col] < -3 ,col] = -3\n","    df.loc[df[col] > 3 ,col] = 3\n","    return df\n","##########################################\n","\n","for col in num_columns:\n","    df_std = outlier_imputation(df_std,col)\n","\n","\n","# --------------------------------------------\n","\n","########################################################################\n","# # IQR Based outlier handling\n","# df_iqr = df_ohe.copy()\n","# q1, q3 = df['table'].quantile([0.25,0.75])\n","# def outlier_imputation_IQR(df,col):\n","#     q1, q3 = df[col].quantile([0.25,0.75])\n","#     iqr = q3 -q1\n","\n","#     df.loc[df[col] < (q1-1.5*iqr),col ] = (q1-1.5*iqr)\n","#     df.loc[df[col] > (q3+1.5*iqr),col ] = (q3+1.5*iqr)\n","#     return df\n","\n","# for col in num_columns:\n","#     df_iqr = outlier_imputation_IQR(df_iqr,col)\n","\n","# df_iqr.describe()\n","\n","########################################################################\n"]},{"cell_type":"markdown","id":"8767d35b","metadata":{"id":"8767d35b"},"source":["# GridSearch"]},{"cell_type":"markdown","id":"543e9bd4","metadata":{"id":"543e9bd4"},"source":["## Ridge Regression"]},{"cell_type":"code","execution_count":null,"id":"f1c0d526","metadata":{"id":"f1c0d526"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","param_grid = {'alpha': [0.01,0.5,1,5],\n","    'max_iter':[100,500,1000,5000]\n","}\n","\n","# Ridge regression using grid search\n","gscv = GridSearchCV(Ridge(random_state=7),param_grid,\n","                scoring='r2',cv=2,verbose=2)\n","\n","gscv.fit(X_train,Y_train)\n","\n","print(gscv.best_score_)\n","\n","print(gscv.best_params_)\n","\n","# Create model with best parameters\n","rg = Ridge(alpha=0.01, max_iter=100, random_state=7)\n","rg.fit(x_train,y_train)\n","Y_pred= rg.predict(X_test)\n","\n","from sklearn.metrics import r2_score\n","\n","print(r2_score(Y_test,Y_pred))\n","\n","# Predict on new data\n","X_test.iloc[0:1,:]\n","log_price = rg.predict(X_test.iloc[0:1,:])"]},{"cell_type":"markdown","id":"78c1b983","metadata":{"id":"78c1b983"},"source":["## Random Forest"]},{"cell_type":"code","execution_count":null,"id":"bc2f3b3f","metadata":{"id":"bc2f3b3f"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","param_grid = {\n","    'n_estimators':[50, 200] ,\n","    'max_samples': [0.6, 0.8]\n","}\n","\n","gscv = GridSearchCV(RandomForestClassifier(max_depth = 4,\n","                                           oob_score=True,\n","                                           class_weight='balanced',\n","                                           random_state=7),\n","                    param_grid, cv=2, verbose=2)\n","\n","gscv.fit(X_train_pca,y_train)\n","\n","gscv.best_score_\n","\n","gscv.best_params_\n","\n","### Create RF  model using best params\n","\n","rfc = RandomForestClassifier(n_estimators = 200,\n","                       max_samples= 0.6,\n","                        max_depth = 4,\n","                        oob_score=True,\n","                        class_weight='balanced',\n","                        random_state=7)\n","\n","rfc.fit(X_train_pca,y_train)\n","\n","y_pred_test = rfc.predict(X_test_pca)\n","\n","from sklearn.metrics import classfication_report\n","classification_report(y_test, y_pred_test)"]},{"cell_type":"code","execution_count":null,"id":"cb9ec87c","metadata":{"id":"cb9ec87c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9f8015f5","metadata":{"id":"9f8015f5"},"outputs":[],"source":["#\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\n","    \"C\" : [0.1, 2],\n","    \"gamma\" : [0.5, 1]\n","}\n","\n","gscv = GridSearchCV(SVC(random_state=7), param_grid, cv=2, verbose=2)\n","\n","\n","gscv.fit(X_train_pca,y_train)\n","gscv.best_score_\n","gscv.best_params_"]},{"cell_type":"code","execution_count":null,"id":"b9476015","metadata":{"id":"b9476015"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"00914816","metadata":{"id":"00914816"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"30f313ff","metadata":{"id":"30f313ff"},"source":["# Simple logistic regression"]},{"cell_type":"code","execution_count":null,"id":"a5dc1c5d","metadata":{"id":"a5dc1c5d"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv(\"BankChurners_cleaned.csv\")\n","\n","X = df.drop(\"Attrition_Flag\",axis = 1)\n","Y = df[\"Attrition_Flag\"]\n","\n","X_ohe = pd.get_dummies(X)\n","\n","Y.value_counts()\n","\n","Y.loc[Y=='Existing Customer'] = 0\n","Y.loc[Y=='Attrited Customer'] = 1\n","\n","Y.value_counts()\n","Y.dtype\n","Y = Y.astype(\"int\")\n","Y.dtype\n","\n","# Train Test Split\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X_ohe,Y,test_size = 0.3 ,random_state = 7,stratify = Y)\n","\n","# Apply Logistic regression / logit classifier\n","###### class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)[source]Â¶\n","\n","#n_jobs = if you want to run multiclass classifier, or how many threads you want to run\n","#l1_ratio\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","lr = LogisticRegression(penalty = 'elasticnet',class_weight = 'balanced',random_state = 7, solver = 'saga',max_iter = 100,l1_ratio = 0.5)\n","# elasticnet = 0.5l1 +0.5l2\n","\n","lr.fit(X_train,Y_train)\n","\n","# convergenceWarning = loss is not minimum, till now the best boundary is not found\n","# model convergence = convergence = means achieving optimial soln. here achieving minimum loss.\n","\n","Y_pred = lr.predict(X_test)\n","\n","# Evaluation\n","## confusion matrix\n","### sklearn.metrics.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n","\n","from sklearn.metrics import confusion_matrix\n","\n","confusion_matrix(Y_test,Y_pred)\n","\n","# true negative false positive\n","# false negative true positive\n","\n","# true positive is 0 becuse our model is not converged yet.\n","\n","\n","\n"]},{"cell_type":"markdown","id":"37e5e3cf","metadata":{"id":"37e5e3cf"},"source":["# End to End classification"]},{"cell_type":"code","execution_count":null,"id":"40fadb90","metadata":{"id":"40fadb90"},"outputs":[],"source":["import pandas as pd\n","\n","# Check The Data given by Competetion\n","#training data : all columns\n","#Consider training data as full data and train test split on it\n","#test data : target columns missing : can't be used to evaluate our model\n","\n","train_df = pd.read_csv(\"train_jRxnrHD.csv\")\n","train_df.info()\n","test_df = pd.read_csv(\"test_QaJU1Mh.csv\")\n","test_df.info()\n","\n","# Split the data\n","\n","data = train_df.copy()\n","\n","## Here target is in column 12 'target'\n","#Premium is another target column which can be predicted for regression problem / multi-class problem\n","\n","X = data.drop(['premium', 'target'], axis=1)\n","y = data.loc[:,'target']\n","\n","X.shape, y.shape\n","\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,\n","                 test_size=0.3,\n","                 random_state=7,\n","                 stratify=y)\n","\n","X_train.shape,X_test.shape,y_train.shape,y_test.shape\n","\n","y.value_counts(normalize=True)\n","y_train.value_counts(normalize=True)\n","y_test.value_counts(normalize=True)\n","\n","# Preprocessing\n","\n","#- Remove the id columns or columns with unique values\n","#- here remove id column\n","#- Remove columns which contain ONLY one value\n","#- Remove columns / rows containing NAs more than threshold\n","#- Fill missing values with median\n","#- Encode the string columns\n","\n","\n","## Remove the id columns or columns with unique values\n","\n","drop_columns = ['id']\n","X_train.drop(drop_columns,axis=1,inplace=True)\n","\n","## columns which contain ONLY one value\n","\n","#NO columns\n","\n","X_train.nunique()\n","\n","## columns / rows containing NAs more than threshold\n","\n","#NO columns\n","\n","X_train.isna().sum()/ X_train.shape[0]\n","\n","## Fill missing values with median\n","\n","X_train.median()\n","X_train.mode() #it will be used if na values are there in string type columns\n","\n","fill_value = X_train.median()\n","X_train.fillna(fill_value, inplace=True)\n","\n","# Encode the string columns\n","\n","#- ONE hot encoding\n","\n","X_train.select_dtypes(include='object').columns\n","X_train = pd.get_dummies(X_train)\n","X_train.shape\n","X_train.columns\n","\n","## Standardization\n","\n","##ONLY on numeric columns and not for categorical columns\n","\n","cat_columns = ['sourcing_channel', 'residence_area_type']\n","num_columns = ['perc_premium_paid_by_cash_credit', 'age_in_days', 'Income',\n","       'Count_3-6_months_late', 'Count_6-12_months_late',\n","       'Count_more_than_12_months_late', 'application_underwriting_score',\n","       'no_of_premiums_paid']\n","\n","from sklearn.preprocessing import StandardScaler\n","std = StandardScaler()\n","std.fit(X_train.loc[:, num_columns])\n","\n","X_train_sc = X_train.copy()\n","std.fit(X_train_sc.loc[:, num_columns])\n","X_train_sc.loc[:, num_columns] = std.transform(X_train_sc.loc[:, num_columns])\n","X_train_sc.shape, X_train.shape\n","\n","\n","# Outlier Handling\n","#- impute the outliers in numeric columns using IQR method\n","\n","def outlier_imputation(df,col):\n","    df.loc[df[col] < -3 ,col] = -3\n","    df.loc[df[col] > 3 ,col] = 3\n","    return df\n","\n","for col in num_columns:\n","    df_std = outlier_imputation(df_std,col)\n","\n","\n","\n","# Feature Selection\n","\n","#- PCA\n","#- RFE\n","#- SelectFromModel ( Decision Tree)\n","\n","## PCA\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components = 0.99, random_state=7)\n","pca.fit(X_train_sc)\n","X_train_pca = pca.transform(X_train_sc)\n","X_train_pca.shape\n","\n","# Train the model\n","\n","#- SVM\n","#fine tune C and gamma parameters\n","#- RandomForest\n","# n_estimators , max_samples , max_depth needs to be tuned\n","#- CatBoost\n","\n","## SVM classifier ( SVC)\n","\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","param_grid = {\n","    \"C\" : [0.1, 2],\n","    \"gamma\" : [0.5, 1]\n","}\n","\n","gscv = GridSearchCV(SVC(random_state=7), param_grid, cv=2, verbose=2)\n","gscv.fit(X_train_pca,y_train)\n","gscv.best_score_\n","gscv.best_params_\n","\n","## RandomForest\n","\n","from sklearn.ensemble import RandomForestClassifier\n","param_grid = {\n","    'n_estimators':[50, 200] ,\n","    'max_samples': [0.6, 0.8]\n","}\n","\n","gscv = GridSearchCV(RandomForestClassifier(max_depth = 4,\n","                                           oob_score=True,\n","                                           class_weight='balanced',\n","                                           random_state=7),\n","                    param_grid, cv=2, verbose=2)\n","\n","gscv.fit(X_train_pca,y_train)\n","\n","gscv.best_score_\n","gscv.best_params_\n","\n","### Create RF  model using best params\n","\n","rfc = RandomForestClassifier(n_estimators = 200,\n","                       max_samples= 0.6,\n","                        max_depth = 4,\n","                        oob_score=True,\n","                        class_weight='balanced',\n","                        random_state=7)\n","\n","rfc.fit(X_train_pca,y_train)\n","\n","### predict on train data only because test data is not preprocessed\n","\n","y_pred_train = rfc.predict(X_train_pca)\n","\n","from sklearn.metrics import f1_score\n","f1_score(y_train, y_pred_train)\n","\n","# Make Test Data Ready fore predictions\n","#same steps of preprocessing as that of training data are done\n","#same features are selected here\n","\n","\n","X_test.drop(drop_columns, axis=1,inplace=True)\n","X_test.fillna(fill_value, inplace=True)\n","X_test_ohe = pd.get_dummies(X_test)\n","#X_test_ohe.shape, X_test.shape\n","X_test_ohe.loc[:, num_columns] = std.transform(X_test_ohe.loc[:, num_columns])\n","#X_test_ohe.shape\n","X_test_ohe.describe()\n","\n","### feature selection using PCA for test data\n","\n","X_test_pca = pca.transform(X_test_ohe)\n","#X_test_pca.shape\n","\n","# prediction on Test data\n","\n","y_pred = rfc.predict(X_test_pca)\n","\n","f1_score(y_test,y_pred)\n","\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test,y_pred))\n","\n","# Apply the model to predict on new data\n","#- apply all the preprocessing steps\n","#- apply feature selection steps\n","\n","\n","rfc.predict(X_test_pca[:1])\n","rfc.predict_proba(X_test_pca[:1])\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}